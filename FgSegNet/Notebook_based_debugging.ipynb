{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Sep 29 22:57:12 2017\n",
    "\n",
    "@author: longang\n",
    "@comments by Zhi Zeng\n",
    "\"\"\"\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Activation, Input, Dropout\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose, UpSampling2D, Cropping2D, MyUpSampling2D\n",
    "\"\"\"\n",
    "Note: The module MyUpSampling2D is written by the author.\n",
    "\"\"\"\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras import regularizers\n",
    "\n",
    "class FgSegNetModule(object):\n",
    "    \n",
    "    def __init__(self, lr, reg, img_shape, scene, vgg_weights_path):\n",
    "        self.lr = lr # Is this the learning rate ??\n",
    "        self.reg = reg # The weight for the l2 regularizer for the Tconv\n",
    "        self.img_shape = img_shape # the shape of the image ??\n",
    "        self.scene = scene # ???\n",
    "        self.vgg_weights_path = vgg_weights_path # the path for the vgg_weights\n",
    "\n",
    "    def VGG16(self, x): \n",
    "        \"\"\"\n",
    "        Note: This defines the structure of the vgg16. Note that each layer has a unique name in the definition.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Block 1\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', data_format='channels_last')(x)\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "        x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "        \"\"\"\n",
    "        Note:\n",
    "        data_format: A string, one of channels_last (default) or channels_first. \n",
    "        The ordering of the dimensions in the inputs. \n",
    "        channels_last corresponds to inputs with shape (batch, height, width, channels) \n",
    "        while channels_first corresponds to inputs with shape (batch, channels, height, width). \n",
    "        It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. \n",
    "        If you never set it, then it will be \"channels_last\".\n",
    "        \"\"\"\n",
    "        # Block 2\n",
    "        x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "        x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "        x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "    \n",
    "        # Block 3\n",
    "        x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "        x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "        x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    \n",
    "        # Block 4\n",
    "        x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "        x = Dropout(0.5, name='dr1')(x)\n",
    "        x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "        x = Dropout(0.5, name='dr2')(x)\n",
    "        x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "        x = Dropout(0.5, name='dr3')(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def transposedConv(self, x):\n",
    "        \"\"\"\n",
    "        Note:\n",
    "        Regularizers allow to apply penalties on layer parameters or layer activity during optimization. \n",
    "        These penalties are incorporated in the loss function that the network optimizes.\n",
    "        The penalties are applied on a per-layer basis. \n",
    "        The exact API will depend on the layer, but the layers Dense, Conv1D, Conv2D and Conv3D have a unified API.\n",
    "        These layers expose 3 keyword arguments:\n",
    "        kernel_regularizer: instance of keras.regularizers.Regularizer\n",
    "        bias_regularizer: instance of keras.regularizers.Regularizer\n",
    "        activity_regularizer: instance of keras.regularizers.Regularizer\n",
    "        Example\n",
    "        from keras import regularizers\n",
    "        model.add(Dense(64, input_dim=64,\n",
    "                        kernel_regularizer=regularizers.l2(0.01),\n",
    "                        activity_regularizer=regularizers.l1(0.01)))\n",
    "        Available penalties\n",
    "        keras.regularizers.l1(0.)\n",
    "        keras.regularizers.l2(0.)\n",
    "        keras.regularizers.l1_l2(0.)\n",
    "        For each of the Tconv block, there is a regularizer. \n",
    "        I am not sure why the regularizer should be used here?\n",
    "        \"\"\"\n",
    "        \n",
    "        # block 5\n",
    "        x = Conv2DTranspose(64, (1, 1), activation='relu', padding='same', name='block5_tconv1', \n",
    "                            kernel_regularizer=regularizers.l2(self.reg))(x)\n",
    "        x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same', name='block5_tconv2')(x)\n",
    "        x = Conv2DTranspose(512, (1, 1), activation='relu', padding='same', name='block5_tconv3')(x)\n",
    "        \n",
    "        # block 6\n",
    "        x = Conv2DTranspose(64, (1, 1), activation='relu', padding='same', name='block6_tconv1', \n",
    "                            kernel_regularizer=regularizers.l2(self.reg))(x)\n",
    "        x = Conv2DTranspose(64, (5, 5), strides=(2, 2), activation='relu', padding='same', name='block6_tconv2')(x)\n",
    "        x = Conv2DTranspose(256, (1, 1), activation='relu', padding='same', name='block6_tconv3')(x)\n",
    "        \n",
    "        # block 7\n",
    "        x = Conv2DTranspose(64, (1, 1), activation='relu', padding='same', name='block7_tconv1', \n",
    "                            kernel_regularizer=regularizers.l2(self.reg))(x)\n",
    "        x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same', name='block7_tconv2')(x)\n",
    "        x = Conv2DTranspose(128, (1, 1), activation='relu', padding='same', name='block7_tconv3')(x)\n",
    "        \n",
    "        # block 8\n",
    "        x = Conv2DTranspose(64, (5, 5), strides=(2, 2), activation='relu', padding='same', name='block8_conv1', \n",
    "                            kernel_regularizer=regularizers.l2(self.reg))(x)\n",
    "        \n",
    "        # block 9\n",
    "        x = Conv2DTranspose(1, (1, 1), padding='same', name='block9_conv1')(x)\n",
    "        x = Activation('sigmoid')(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def initModel (self):\n",
    "        h, w, d = self.img_shape # height width dimension\n",
    "        \n",
    "        input_1 = Input(shape=(h, w, d), name='ip_scale1')\n",
    "        vgg_layer_output = self.VGG16(input_1)\n",
    "        shared_model = Model(inputs=input_1, outputs=vgg_layer_output, name='shared_model')\n",
    "        shared_model.load_weights(self.vgg_weights_path, by_name=True)\n",
    "        \"\"\"\n",
    "        Note:\n",
    "        model.load_weights(filepath, by_name=False): \n",
    "        loads the weights of the model from a HDF5 file (created by save_weights). \n",
    "        By default, the architecture is expected to be unchanged. \n",
    "        To load weights into a different architecture (with some layers in common), \n",
    "        use by_name=True to load only those layers with the same name.\n",
    "        \"\"\"\n",
    "        \n",
    "        unfreeze_layers = ['block4_conv1','block4_conv2', 'block4_conv3']\n",
    "        for layer in shared_model.layers:\n",
    "            if(layer.name not in unfreeze_layers):\n",
    "                layer.trainable = False\n",
    "        \"\"\"\n",
    "        Note:\n",
    "        Only the last block of the encoder will be trained.\n",
    "        \"\"\"\n",
    "                \n",
    "        # Scale 1\n",
    "        x1_ups = {'streetCornerAtNight':(0,1), 'tramStation':(1,0), 'turbulence2':(1,0)} # ???\n",
    "        x1 = shared_model.output\n",
    "        \"\"\"\n",
    "        Cropping2D   \n",
    "        keras.layers.Cropping2D(cropping=((0, 0), (0, 0)), data_format=None)\n",
    "        Cropping layer for 2D input (e.g. picture).\n",
    "        It crops along spatial dimensions, i.e. width and height.\n",
    "        Arguments\n",
    "        cropping: int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n",
    "        If int: the same symmetric cropping is applied to width and height.\n",
    "        If tuple of 2 ints: interpreted as two different symmetric cropping values for height and width: \n",
    "            (symmetric_height_crop, symmetric_width_crop).\n",
    "        If tuple of 2 tuples of 2 ints: interpreted as ((top_crop, bottom_crop), (left_crop, right_crop))\n",
    "        data_format: A string, one of channels_last (default) or channels_first. \n",
    "        Examples\n",
    "        # Crop the input 2D images or feature maps\n",
    "        model = Sequential()\n",
    "        model.add(Cropping2D(cropping=((2, 2), (4, 4)),\n",
    "                             input_shape=(28, 28, 3)))\n",
    "        # now model.output_shape == (None, 24, 20, 3)\n",
    "        model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "        model.add(Cropping2D(cropping=((2, 2), (2, 2))))\n",
    "        # now model.output_shape == (None, 20, 16. 64)\n",
    "        \"\"\"\n",
    "        if(self.scene=='wetSnow'):\n",
    "            x1 = Cropping2D(cropping=((1, 2),(0, 0)))(x1)\n",
    "        elif(self.scene=='skating'):\n",
    "            x1 = Cropping2D(cropping=((1, 1),(1, 2)))(x1)\n",
    "        else:\n",
    "            for key, val in x1_ups.items():\n",
    "                if self.scene==key:\n",
    "                    # upscale by adding number of pixels to each dim.\n",
    "                    x1 = MyUpSampling2D(size=(1,1), num_pixels=val)(x1)\n",
    "                    break\n",
    "        \"\"\"\n",
    "        Note:\n",
    "        For the first scale, only expending operations are used.\n",
    "        \"\"\"\n",
    "            \n",
    "        # Scale 2\n",
    "        x2_ups = {'tunnelExit_0_35fps':(0,1),'tramCrossroad_1fps':(1,0),'bridgeEntry':(1,1),\n",
    "                  'busyBoulvard':(1,0),'fluidHighway':(0,1),'streetCornerAtNight':(1,1), \n",
    "                  'tramStation':(2,0),'winterStreet':(1,0),'twoPositionPTZCam':(1,0),\n",
    "                  'peopleInShade':(1,1),'turbulence2':(1,1),'turbulence3':(1,0),\n",
    "                  'skating':(1,1), 'wetSnow':(0,0)}\n",
    "        \n",
    "        input_2 = Input(shape=(int(h/2), int(w/2), d), name='ip_scale2')\n",
    "        x2 = shared_model(input_2)\n",
    "        x2 = UpSampling2D((2,2))(x2)\n",
    "        for key, val in x2_ups.items():\n",
    "            if self.scene == key and self.scene in ['skating', 'wetSnow']:\n",
    "                x2 = Cropping2D(cropping=((1, 1), val))(x2)\n",
    "                break\n",
    "            elif self.scene==key:\n",
    "                x2 = MyUpSampling2D(size=(1, 1), num_pixels=val)(x2)\n",
    "                break\n",
    "        \"\"\"\n",
    "        Note:\n",
    "        Multiple input fashion in Keras. Nothing but updating and expending.\n",
    "        \"\"\"\n",
    "            \n",
    "        # Scale 3\n",
    "        x3_ups = {'tunnelExit_0_35fps':(2,3),'tramCrossroad_1fps':(3,0),'bridgeEntry':(3,1,),\n",
    "                  'busyBoulvard':(3,0),'fluidHighway':(0,3),'streetCornerAtNight':(1,1),\n",
    "                  'tramStation':(2,0),'winterStreet':(1,0),'twoPositionPTZCam':(1,2),\n",
    "                  'peopleInShade':(1,3),'turbulence2':(3,1),'turbulence3':(1,0),\n",
    "                  'office':(0,2), 'pedestrians':(0,2), 'bungalows':(0,2), 'busStation':(0,2)}\n",
    "                \n",
    "        input_3 = Input(shape=(int(h/4), int(w/4), d), name='ip_scale3')\n",
    "        x3 = shared_model(input_3)\n",
    "        x3 = UpSampling2D((4,4))(x3)\n",
    "        for key, val in x3_ups.items():\n",
    "            if self.scene==key:\n",
    "                x3 = MyUpSampling2D(size=(1,1), num_pixels=val)(x3)\n",
    "                break\n",
    "        \"\"\"\n",
    "        Note:\n",
    "        Nothing but upsampling and expending.\n",
    "        \"\"\"\n",
    "            \n",
    "        # concatenate feature maps\n",
    "        top = keras.layers.concatenate([x1, x2, x3], name='feature_concat')\n",
    "        if(self.scene=='wetSnow'):\n",
    "            top = MyUpSampling2D(size=(1,1), num_pixels=(3,0))(top)\n",
    "        elif(self.scene=='skating'):\n",
    "            top = MyUpSampling2D(size=(1,1), num_pixels=(2,3))(top)\n",
    "        \"\"\"\n",
    "        Note:\n",
    "        Concatenate and expending\n",
    "        \"\"\"\n",
    "        \n",
    "        # Transposed Conv\n",
    "        top = self.transposedConv(top)\n",
    "        # i chose this crazy upscaling/cropping way\n",
    "        if(self.scene=='tramCrossroad_1fps'):\n",
    "            top = MyUpSampling2D(size=(1,1), num_pixels=(2,0))(top)\n",
    "        elif(self.scene=='bridgeEntry'):\n",
    "            top = MyUpSampling2D(size=(1,1), num_pixels=(2,2))(top)\n",
    "        elif(self.scene=='fluidHighway'):\n",
    "            top = MyUpSampling2D(size=(1,1), num_pixels=(2,0))(top)\n",
    "        elif(self.scene=='streetCornerAtNight'): \n",
    "            top = MyUpSampling2D(size=(1,1), num_pixels=(1,0))(top)\n",
    "            top = Cropping2D(cropping=((0, 0),(0, 1)))(top)\n",
    "        elif(self.scene=='tramStation'):  \n",
    "            top = Cropping2D(cropping=((1, 0),(0, 0)))(top)\n",
    "        elif(self.scene=='twoPositionPTZCam'):\n",
    "            top = MyUpSampling2D(size=(1,1), num_pixels=(0,2))(top)\n",
    "        elif(self.scene=='turbulence2'):\n",
    "            top = Cropping2D(cropping=((1, 0),(0, 0)))(top)\n",
    "            top = MyUpSampling2D(size=(1,1), num_pixels=(0,1))(top)\n",
    "        elif(self.scene=='turbulence3'):\n",
    "            top = MyUpSampling2D(size=(1,1), num_pixels=(2,0))(top)\n",
    "\n",
    "        vision_model = Model(inputs=[input_1, input_2, input_3], outputs=top, name='vision_model')\n",
    "        opt = keras.optimizers.RMSprop(lr = self.lr, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "        vision_model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "        return vision_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
